services:
  bot:
    image: pha123661/emoji-lm-line-bot
    container_name: emoji-lm-line-bot
    environment:
      - LINE_CHANNEL_SECRET=${LINE_CHANNEL_SECRET}
      - LINE_CHANNEL_ACCESS_TOKEN=${LINE_CHANNEL_ACCESS_TOKEN}
      - HF_API_TOKEN_LIST=${HF_API_TOKEN_LIST}
    ports:
      - "8000:8000" # Not necessary since we use ngrok

  ngrok:
    image: ngrok/ngrok:latest
    container_name: emojilm-ngrok
    environment:
      NGROK_AUTHTOKEN: ${NGROK_AUTHTOKEN}
    command:
      - "http"
      - "http://bot:8000"
      - "--log=stdout"

  llama-cpp-server:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: emojilm-llama-cpp-server
    volumes:
      - ./llama-cpp-server:/models
    environment:
      - LLAMA_ARG_HOST=0.0.0.0
      - LLAMA_ARG_PORT=7777
      - LLAMA_ARG_MODEL=${LLAMA_ARG_MODEL}
      - LLAMA_ARG_CHAT_TEMPLATE_FILE=${LLAMA_ARG_CHAT_TEMPLATE_FILE}
      - LLAMA_ARG_N_PREDICT=${LLAMA_ARG_N_PREDICT}

    command: >
      --jinja
